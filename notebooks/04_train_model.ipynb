{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e960487-a6f0-4aca-848f-5df1701c4934",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: 32000204 rows\n✅ Model trained\n✅ Model saved\n\uD83D\uDCCA RMSE on test set: 0.8089\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Load training data\n",
    "df = spark.table(\"workspace.gold.fact_ratings\").select(\"userId\", \"movieId\", \"rating\")\n",
    "\n",
    "# Cache for performance\n",
    "#df.cache() # --> commented because doesn't work in databricks free specifically\n",
    "print(f\"Training data: {df.count()} rows\")\n",
    "\n",
    "# Train/test split\n",
    "(training, test) = df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Build ALS model\n",
    "als = ALS(\n",
    "    userCol=\"userId\",\n",
    "    itemCol=\"movieId\",\n",
    "    ratingCol=\"rating\",\n",
    "    maxIter=10,\n",
    "    regParam=0.1,\n",
    "    rank=10,\n",
    "    coldStartStrategy=\"drop\",  \n",
    "    nonnegative=True\n",
    ")\n",
    "\n",
    "model = als.fit(training)\n",
    "print(\"✅ Model trained\")\n",
    "\n",
    "# Save to a Unity Catalog Volume\n",
    "model.write().overwrite().save(\"/Volumes/workspace/default/movielens_raw/models/als_model\")\n",
    "print(\"✅ Model saved\")\n",
    "\n",
    "# Evaluate\n",
    "predictions = model.transform(test)\n",
    "evaluator = RegressionEvaluator(\n",
    "    metricName=\"rmse\",\n",
    "    labelCol=\"rating\",\n",
    "    predictionCol=\"prediction\"\n",
    ")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(f\"\uD83D\uDCCA RMSE on test set: {rmse:.4f}\")\n",
    "\n",
    "# Unpersist cached data \n",
    "#df.unpersist() # --> commented because doesn't work in databricks free specifically\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cbfd5bd1-3b5b-4744-8277-732cad8a4588",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model loaded\n✅ Recommendations for 100 users\n\n--- Top 10 for first user ---\n+-------+------+----------+-------------------------------------------------------------------------------------+\n|movieId|userId|prediction|title                                                                                |\n+-------+------+----------+-------------------------------------------------------------------------------------+\n|240070 |5029  |5.7764626 |SpongeBob SquarePants: Heroes of Bikini Bottom (2011)                                |\n|240054 |5029  |5.7764626 |SpongeBob SquarePants: Tide and Seek                                                 |\n|270306 |5029  |5.7764626 |WWE: The Triumph and Tragedy of World Class Championship Wrestling (2007)            |\n|177209 |5029  |5.63747   |Acı Aşk (2009)                                                                       |\n|177209 |5029  |5.63747   |Acı Aşk (2009)                                                                       |\n|194434 |5029  |5.612992  |Adrenaline (1990)                                                                    |\n|222368 |5029  |5.5443206 |Crazy Romance (2019)                                                                 |\n|222368 |5029  |5.5443206 |Crazy Romance (2019)                                                                 |\n|231287 |5029  |5.3665175 |LIFE BEYOND: Chapter 1. Alien life, deep time, and our place in cosmic history (2019)|\n|219031 |5029  |5.3665175 |Pornography: A Secret History of Civilisation (1999)                                 |\n+-------+------+----------+-------------------------------------------------------------------------------------+\nonly showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.recommendation import ALS, ALSModel\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql.functions import col, row_number\n",
    "from pyspark.sql import Window\n",
    "\n",
    "# Pick top 100 power users (or any sample)\n",
    "sample_users = (\n",
    "    spark.table(\"workspace.gold.dim_users\")\n",
    "    .filter(\"is_power_user = true\")\n",
    "    .orderBy(col(\"total_ratings\").desc())\n",
    "    .select(\"userId\")\n",
    "    .limit(100)\n",
    ")\n",
    "\n",
    "# Get all movie IDs\n",
    "all_movies = spark.table(\"workspace.gold.fact_ratings\").select(\"movieId\").distinct()\n",
    "\n",
    "# Create all user-movie pairs for the sample\n",
    "user_movie_pairs = sample_users.crossJoin(all_movies)\n",
    "\n",
    "# Predict\n",
    "model = ALSModel.load(\"/Volumes/workspace/default/movielens_raw/models/als_model\")\n",
    "print(\"✅ Model loaded\")\n",
    "predictions = model.transform(user_movie_pairs).filter(col(\"prediction\").isNotNull())\n",
    "\n",
    "# Top 10 per user\n",
    "window = Window.partitionBy(\"userId\").orderBy(col(\"prediction\").desc())\n",
    "\n",
    "user_recs = (\n",
    "    predictions\n",
    "    .withColumn(\"rank\", row_number().over(window))\n",
    "    .filter(col(\"rank\") <= 10)\n",
    "    .drop(\"rank\")\n",
    ")\n",
    "\n",
    "user_recs.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"workspace.gold.user_recommendations\")\n",
    "print(f\"✅ Recommendations for {sample_users.count()} users\")\n",
    "\n",
    "# Show sample with movie titles\n",
    "print(\"\\n--- Top 10 for first user ---\")\n",
    "first_user = user_recs.select(\"userId\").first()[0]\n",
    "(\n",
    "    user_recs\n",
    "    .filter(col(\"userId\") == first_user)\n",
    "    .join(spark.table(\"workspace.gold.dim_movies_enriched\").select(\"movieId\", \"title\"), on=\"movieId\")\n",
    "    .orderBy(col(\"prediction\").desc())\n",
    "    .show(10, truncate=False)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "04_train_model",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}